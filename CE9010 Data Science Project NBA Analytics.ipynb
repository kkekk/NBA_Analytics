{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CE9010 Introduction to Data Science Project\n",
    "\n",
    "# Data Scraper\n",
    "\n",
    "\n",
    "\n",
    "First, we import the relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs4 import Comment, BeautifulSoup as bs\n",
    "import urllib.request\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO BE FORMATTED \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n",
    "\n",
    "\n",
    "Data Acquisition\n",
    " ------\n",
    "\n",
    "#### Warning, long runtime of up to 40 minutes. Program will finish scraping when END OF YEAR: 2016 is printed.\n",
    "\n",
    "Scraper written in beautifulsoup.\n",
    "\n",
    "#### Types of data extracted\n",
    "---\n",
    "\n",
    "Our main goal of our is to predict the impact of college prospects in the first and second year of NBA based on their college stats. Hence we choose to use their advanced stats available in college (ws, ws/40min) to generalize the impact on NBA measured in their advanced stats available in the NBA (per, ws, ws/48, bpm, vorp) for their first two years in the league. We chose to extract data from 1996 as college advanced statistics were only available from the 1995 season onwards. We also chose to only include the first 30 draft picks of each draft as players beyond the 30th picks usually do not play significant minutes in their teams.\n",
    "\n",
    "Player's NBA stats extracted from [Basketball Reference](https://www.basketball-reference.com/).\n",
    "\n",
    "Player's College stats extracted from [Sports Reference](https://www.sports-reference.com/)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "#### Problems encountered\n",
    "\n",
    "---\n",
    "\n",
    "The main problem encountered when running the scraper is the long runtime for a relatively small dataset est <200? confirm again>. The bottleneck occurs when parsing the whole page to look for the link to the sports reference website for each player in order to acquire their respective college stats. Having to parse the whole page for every player leads to a long runtime; inefficient code. A better solution would be to use another data scraping framework such as Scrapy which allows data extraction using [selectors](https://doc.scrapy.org/en/latest/topics/selectors.html). Extracting the link to sports-reference website of the page using the XPath or CSS selector would be much quicker than parsing the entire page. However as this scraper would only need to be run once it is not a major concern to optimize and rewrite another scraper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_comments(inside_html, html_id):\n",
    "    comments = inside_html.findAll(text=lambda text:isinstance(text, Comment)) #data we want is commented, hence the need \n",
    "    comments = [comment.extract() for comment in comments if 'id=\\\"' + html_id + '\\\"' in comment.extract()] #get advanced stats table\n",
    "    return bs(comments[0], 'html.parser')\n",
    "\n",
    "def read_url_into_soup(url):\n",
    "    next_page = urllib.request.urlopen(url).read() # goes to player page\n",
    "    return bs(next_page, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allen Iverson\n",
      "Marcus Camby\n",
      "Shareef Abdur-Rahim\n",
      "Stephon Marbury\n",
      "Ray Allen\n",
      "Antoine Walker\n",
      "Lorenzen Wright\n",
      "Kerry Kittles\n",
      "Samaki Walker\n",
      "Erick Dampier\n",
      "Todd Fuller\n",
      "Vitaly Potapenko\n",
      "Steve Nash\n",
      "Tony Delk\n",
      "John Wallace\n",
      "Walter McCarty\n",
      "Roy Rogers\n",
      "Derek Fisher\n",
      "Jerome Williams\n",
      "Brian Evans\n",
      "Priest Lauderdale\n",
      "Travis Knight\n",
      "END OF YEAR: 1996\n",
      "\n",
      "Tim Duncan\n",
      "Keith Van Horn\n",
      "Chauncey Billups\n",
      "Antonio Daniels\n",
      "Tony Battie\n",
      "Ron Mercer\n",
      "Tim Thomas\n",
      "Adonal Foyle\n",
      "Danny Fortson\n",
      "Tariq Abdul-Wahad\n",
      "Austin Croshere\n",
      "Derek Anderson\n",
      "Maurice Taylor\n",
      "Kelvin Cato\n",
      "Brevin Knight\n",
      "Johnny Taylor\n",
      "Scot Pollard\n",
      "Paul Grant\n",
      "Anthony Parker\n",
      "Ed Gray\n",
      "Bobby Jackson\n",
      "Rodrick Rhodes\n",
      "John Thomas\n",
      "Charles Smith\n",
      "Jacque Vaughn\n",
      "Keith Booth\n",
      "END OF YEAR: 1997\n",
      "\n",
      "Michael Olowokandi\n",
      "Mike Bibby\n",
      "Raef LaFrentz\n",
      "Antawn Jamison\n",
      "Vince Carter\n",
      "Robert Traylor\n",
      "Jason Williams\n",
      "Larry Hughes\n",
      "Paul Pierce\n",
      "Bonzi Wells\n",
      "Michael Doleac\n",
      "Keon Clark\n",
      "Michael Dickerson\n",
      "Matt Harpring\n",
      "Bryce Drew\n",
      "Pat Garrity\n",
      "Roshown McLeod\n",
      "Ricky Davis\n",
      "Brian Skinner\n",
      "Tyronn Lue\n",
      "Felipe Lopez\n",
      "Sam Jacobson\n",
      "Corey Benjamin\n",
      "Nazr Mohammed\n",
      "END OF YEAR: 1998\n",
      "\n",
      "Elton Brand\n",
      "Steve Francis\n",
      "Baron Davis\n",
      "Lamar Odom\n",
      "Wally Szczerbiak\n",
      "Richard Hamilton\n",
      "Andre Miller\n",
      "Shawn Marion\n",
      "Jason Terry\n",
      "Trajan Langdon\n",
      "Aleksandar Radojevic\n",
      "Corey Maggette\n",
      "William Avery\n",
      "Metta World Peace\n",
      "Cal Bowdler\n",
      "James Posey\n",
      "Quincy Lewis\n",
      "Dion Glover\n",
      "Jeff Foster\n",
      "Kenny Thomas\n",
      "Devean George\n",
      "Tim James\n",
      "Vonteego Cummings\n",
      "Jumaine Jones\n",
      "Scott Padgett\n",
      "END OF YEAR: 1999\n",
      "\n",
      "Kenyon Martin\n",
      "Stromile Swift\n",
      "Marcus Fizer\n",
      "Mike Miller\n",
      "DerMarr Johnson\n",
      "Chris Mihm\n",
      "Jamal Crawford\n",
      "Joel Przybilla\n",
      "Keyon Dooling\n",
      "Jerome Moiso\n",
      "Etan Thomas\n",
      "Courtney Alexander\n",
      "Mateen Cleaves\n",
      "Jason Collier\n",
      "Desmond Mason\n",
      "Quentin Richardson\n",
      "Jamaal Magloire\n",
      "Speedy Claxton\n",
      "Morris Peterson\n",
      "Donnell Harvey\n",
      "Mamadou N'Diaye\n",
      "Erick Barkley\n",
      "Mark Madsen\n",
      "END OF YEAR: 2000\n",
      "\n",
      "Jason Richardson\n",
      "Shane Battier\n",
      "Eddie Griffin\n",
      "Rodney White\n",
      "Joe Johnson\n",
      "Kedrick Brown\n",
      "Richard Jefferson\n",
      "Troy Murphy\n",
      "Steven Hunter\n",
      "Kirk Haston\n",
      "Michael Bradley\n",
      "Jason Collins\n",
      "Zach Randolph\n",
      "Brendan Haywood\n",
      "Joseph Forte\n",
      "Jeryl Sasser\n",
      "Brandon Armstrong\n",
      "Gerald Wallace\n",
      "Samuel Dalembert\n",
      "Jamaal Tinsley\n",
      "END OF YEAR: 2001\n",
      "\n",
      "Mike Dunleavy\n",
      "Drew Gooden\n",
      "Dajuan Wagner\n",
      "Chris Wilcox\n",
      "Caron Butler\n",
      "Jared Jeffries\n",
      "Melvin Ely\n",
      "Marcus Haislip\n",
      "Fred Jones\n",
      "Juan Dixon\n",
      "Curtis Borchardt\n",
      "Ryan Humphrey\n",
      "Kareem Rush\n",
      "Qyntel Woods\n",
      "Casey Jacobsen\n",
      "Tayshaun Prince\n",
      "Frank Williams\n",
      "John Salmons\n",
      "Chris Jefferies\n",
      "Dan Dickau\n",
      "END OF YEAR: 2002\n",
      "\n",
      "Carmelo Anthony\n",
      "Chris Bosh\n",
      "Dwyane Wade\n",
      "Chris Kaman\n",
      "Kirk Hinrich\n",
      "T.J. Ford\n",
      "Mike Sweetney\n",
      "Jarvis Hayes\n",
      "Nick Collison\n",
      "Marcus Banks\n",
      "Luke Ridnour\n",
      "Reece Gaines\n",
      "David West\n",
      "Dahntay Jones\n",
      "Brian Cook\n",
      "Josh Howard\n",
      "END OF YEAR: 2003\n",
      "\n",
      "Emeka Okafor\n",
      "Ben Gordon\n",
      "Devin Harris\n",
      "Josh Childress\n",
      "Luol Deng\n",
      "Rafael Araujo\n",
      "Andre Iguodala\n",
      "Luke Jackson\n",
      "Kris Humphries\n",
      "Kirk Snyder\n",
      "Jameer Nelson\n",
      "Delonte West\n",
      "Tony Allen\n",
      "Kevin Martin\n",
      "David Harrison\n",
      "END OF YEAR: 2004\n",
      "\n",
      "Andrew Bogut\n",
      "Marvin Williams\n",
      "Deron Williams\n",
      "Chris Paul\n",
      "Raymond Felton\n",
      "Charlie Villanueva\n",
      "Channing Frye\n",
      "Ike Diogu\n",
      "Sean May\n",
      "Rashad McCants\n",
      "Antoine Wright\n",
      "Joey Graham\n",
      "Danny Granger\n",
      "Hakim Warrick\n",
      "Julius Hodge\n",
      "Nate Robinson\n",
      "Jarrett Jack\n",
      "Francisco Garcia\n",
      "Luther Head\n",
      "Jason Maxiell\n",
      "Linas Kleiza\n",
      "Wayne Simien\n",
      "David Lee\n",
      "END OF YEAR: 2005\n",
      "\n",
      "LaMarcus Aldridge\n",
      "Adam Morrison\n",
      "Tyrus Thomas\n"
     ]
    }
   ],
   "source": [
    "f = open(\"data/nba_all.csv\", \"w\") \n",
    "f2 = open(\"data/college_all.csv\", \"w\") \n",
    "writer = csv.writer(f)\n",
    "writerf = csv.writer(f2)    \n",
    "\n",
    "for year in range(1996, 2017):\n",
    "    url = \"https://www.basketball-reference.com/draft/NBA_\"+ str(year) + \".html\"\n",
    "#     req = urllib.request.Request(url)\n",
    "#     html = read_url_into_soup(req)\n",
    "    html = read_url_into_soup(url)\n",
    "#     response = urllib.request.urlopen(req)\n",
    "#     html = response.read()\n",
    "#     html = bs(html, 'html.parser')\n",
    "\n",
    "    \n",
    "    for row in html.table.tbody.findAll(\"tr\"):\n",
    "\n",
    "        if (row.find(\"td\")) is None:\n",
    "            print(\"END OF YEAR: \"+ str(year) +\"\\n\")  # reach end of file\n",
    "            break\n",
    "            \n",
    "        seasons = row.find(\"td\", {\"data-stat\" : \"seasons\"} )\n",
    "        \n",
    "        if (not seasons.get_text() or  #if player did not play in NBA after being drafted\n",
    "        int(seasons.get_text()) < 2 or  # if less than 2 seasons played, skip\n",
    "        len(row.find(\"td\", {\"data-stat\" : \"college_name\"}) ) < 1): #if player played in euroleague\n",
    "            continue\n",
    "            \n",
    "        player = row.find(\"td\",{\"data-stat\" : \"player\"})\n",
    "        print(player.get_text())\n",
    "        inside_html = read_url_into_soup(\"https://www.basketball-reference.com/\" + player.a['href'])\n",
    "#         next_page = urllib.request.urlopen(\"https://www.basketball-reference.com/\" + player.a['href']).read() # goes to player page\n",
    "#         inside_html = bs(next_page, 'html.parser')\n",
    "        \n",
    "        advanced = extract_comments(inside_html, 'advanced')\n",
    "        \n",
    "        # STATS\n",
    "          \n",
    "        out = [player.string]\n",
    "        cols = ['per', 'ws', 'ws_per_48', 'bpm', 'vorp'] # stats to include\n",
    "        for col in cols:\n",
    "            out.append(advanced.findAll('td', {'data-stat' : col})[0].string) #include both 1st and 2nd year\n",
    "            out.append(advanced.findAll('td', {'data-stat' : col})[1].string) \n",
    "        writer.writerow(out)\n",
    "        \n",
    "        for i in inside_html.findAll(\"a\"): #inefficient way of finding the url for college stats\n",
    "            if \"College Basketball\" in str(i):\n",
    "                coll_url = i['href']\n",
    "                break\n",
    "              \n",
    "        coll_html = read_url_into_soup(coll_url)\n",
    "#         coll_page = urllib.request.urlopen(coll_url).read()\n",
    "#         coll_html = bs(coll_page, 'html.parser')\n",
    "\n",
    "        coll_advanced = extract_comments(coll_html, 'players_advanced')\n",
    "#         coll_pg = extract_comments(coll_html, 'players_per_game')\n",
    "        \n",
    "        #input stats\n",
    "        \n",
    "        ws = coll_advanced.findAll('td', {'data-stat' : 'ws'})[-2].string #obtain final year college stats ws and ws40\n",
    "        ws40 = coll_advanced.findAll('td', {'data-stat' : 'ws_per_40'})[-2].string\n",
    "        \n",
    "        sos = coll_html.findAll('td', {'data-stat' : 'sos'})[-2].string\n",
    "        writerf.writerow([player.string, ws, ws40, sos])\n",
    "            \n",
    "f.close()\n",
    "f2.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PYTHON 2.7 CODE BELOW\n",
    "\n",
    "Do not remove in case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.basketball-reference.com/draft/NBA_2016.html\"\n",
    "f = urllib.urlopen(url).read()\n",
    "html = bs(f, 'html.parser')\n",
    "with open(\"2016.txt\",\"w\") as fp:\n",
    "    for row in html.table.findAll(\"td\", {\"data-stat\" : \"player\"}):\n",
    "        print(row.get_text())\n",
    "        next_page = urllib.urlopen(\"https://www.basketball-reference.com/\" + row.a['href']).read()\n",
    "        inside_html = bs(next_page, 'html.parser')\n",
    "        comments = inside_html.findAll(text=lambda text:isinstance(text, Comment)) #data we want is commented, hence the need \n",
    "        comments = [comment.extract() for comment in comments if 'id=\\\"advanced\\\"' in comment.extract()]\n",
    "        advanced = bs(comments[0], 'html.parser')\n",
    "        print(advanced.find('td', {'data-stat' : 'ws'}))\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
