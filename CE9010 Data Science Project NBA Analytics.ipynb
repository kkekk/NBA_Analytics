{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CE9010 Introduction to Data Science Project\n",
    "\n",
    "# NBA Analysis\n",
    "\n",
    "\n",
    "\n",
    "This dataset requires a linear learning algorithm.\n",
    "Model formed at the end of the notebook based on appropriate validation methods used an NBA player's college statistics to predict their 1st and 2nd year impact (measured in advanced statistics).\n",
    "Prediction of player ability is gaining prominence in the NBA with multiple teams having their own analytical department to ensure the player they drafted is indeed the best player at each available pick of the NBA draft."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Data Acquisition\n",
    " ------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Data Collection\n",
    "---\n",
    "Our main goal is to predict the performance of college prospects in their first and second year of NBA based on their college game performance. Hence we chose to use their advanced statistics available from their college play (WS, Strength of schedule), player's basic stats per 40min as data features and their advanced statistics available in the NBA (PER, BPM, VORP) as the dependent variable to predict for their first two years in the league. \n",
    "\n",
    "We chose to extract data from 1996 as college advanced statistics were only available from the 1995 season onwards. We also chose to only include the first 30 draft picks of each draft as players beyond the 30th picks usually do not play significant minutes in their teams.\n",
    "\n",
    "Player's NBA stats extracted from [Basketball Reference](https://www.basketball-reference.com/).\n",
    "\n",
    "Player's College stats extracted from [Sports Reference](https://www.sports-reference.com/)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Legend\n",
    "---\n",
    "PER: Player Efficiency Ratio\n",
    "\n",
    "WS: Win Shares\n",
    "\n",
    "BPM: Box Plus/Minus\n",
    "\n",
    "VORP: Value Over Replacement Player\n",
    "\n",
    "\n",
    "\n",
    "## Data Scraper\n",
    "\n",
    "\n",
    "First, we import the relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs4 import Comment, BeautifulSoup as bs\n",
    "import urllib.request\n",
    "import csv\n",
    "import traceback\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from copy import copy\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_comments(inside_html, html_id):\n",
    "    comments = inside_html.findAll(text=lambda text:isinstance(text, Comment)) #data we want is commented, hence the need \n",
    "    comments = [comment.extract() for comment in comments if 'id=\\\"' + html_id + '\\\"' in comment.extract()] #get advanced stats table\n",
    "    return bs(comments[0], 'html.parser')\n",
    "\n",
    "def read_url_into_soup(url):\n",
    "    try:\n",
    "        next_page = urllib.request.urlopen(url).read() # goes to player page\n",
    "        return bs(next_page, 'html.parser')\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        return read_url_into_soup(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraper\n",
    "----\n",
    "\n",
    "#### Warning, long runtime of up to 40 minutes. Program will finish scraping when END OF YEAR: 2016 is printed.\n",
    "\n",
    "Scraper written using beautifulsoup.\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "#### Problems encountered\n",
    "\n",
    "---\n",
    "\n",
    "The main problem encountered when running the scraper is the long runtime for a relatively small dataset of around 500 data cells. The bottleneck occurs when parsing the whole page to look for the link to the sports reference website for each player in order to acquire their respective college stats. This is very inefficient as having to parse the whole page for every player leads to a long runtime. A better solution would be to use another data scraping framework such as Scrapy which allows data extraction using [selectors](https://doc.scrapy.org/en/latest/topics/selectors.html). Extracting the link to sports-reference website of the page using the XPath or CSS selector would be much quicker than parsing the entire page. However as this scraper would only need to be run once it is not a major concern in our project to optimize and rewrite another scraper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allen Iverson\n",
      "Marcus Camby\n",
      "Shareef Abdur-Rahim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-5-4ab15d5e010c>\", line 8, in read_url_into_soup\n",
      "    next_page = urllib.request.urlopen(url).read() # goes to player page\n",
      "  File \"/usr/lib/python3.5/http/client.py\", line 455, in read\n",
      "    return self._readall_chunked()\n",
      "  File \"/usr/lib/python3.5/http/client.py\", line 561, in _readall_chunked\n",
      "    value.append(self._safe_read(chunk_left))\n",
      "  File \"/usr/lib/python3.5/http/client.py\", line 607, in _safe_read\n",
      "    chunk = self.fp.read(min(amt, MAXAMOUNT))\n",
      "  File \"/usr/lib/python3.5/socket.py\", line 575, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/usr/lib/python3.5/ssl.py\", line 929, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"/usr/lib/python3.5/ssl.py\", line 791, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "  File \"/usr/lib/python3.5/ssl.py\", line 575, in read\n",
      "    v = self._sslobj.read(len, buffer)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stephon Marbury\n",
      "Ray Allen\n",
      "Antoine Walker\n",
      "Lorenzen Wright\n",
      "Kerry Kittles\n",
      "Samaki Walker\n",
      "Erick Dampier\n",
      "Todd Fuller\n",
      "Vitaly Potapenko\n",
      "Steve Nash\n",
      "Tony Delk\n",
      "John Wallace\n",
      "Walter McCarty\n",
      "Roy Rogers\n",
      "Derek Fisher\n",
      "Jerome Williams\n",
      "Brian Evans\n",
      "Priest Lauderdale\n",
      "Travis Knight\n",
      "END OF YEAR: 1996\n",
      "\n",
      "Tim Duncan\n",
      "Keith Van Horn\n",
      "Chauncey Billups\n",
      "Antonio Daniels\n",
      "Tony Battie\n",
      "Ron Mercer\n",
      "Tim Thomas\n",
      "Adonal Foyle\n",
      "Danny Fortson\n",
      "Tariq Abdul-Wahad\n",
      "Austin Croshere\n",
      "Derek Anderson\n",
      "Maurice Taylor\n",
      "Kelvin Cato\n",
      "Brevin Knight\n",
      "Johnny Taylor\n",
      "Scot Pollard\n",
      "Paul Grant\n",
      "Anthony Parker\n",
      "Ed Gray\n",
      "Bobby Jackson\n",
      "Rodrick Rhodes\n",
      "John Thomas\n",
      "Charles Smith\n",
      "Jacque Vaughn\n",
      "Keith Booth\n",
      "END OF YEAR: 1997\n",
      "\n",
      "Michael Olowokandi\n",
      "Mike Bibby\n",
      "Raef LaFrentz\n",
      "Antawn Jamison\n",
      "Vince Carter\n",
      "Robert Traylor\n",
      "Jason Williams\n",
      "Larry Hughes\n",
      "Paul Pierce\n",
      "Bonzi Wells\n",
      "Michael Doleac\n",
      "Keon Clark\n",
      "Michael Dickerson\n",
      "Matt Harpring\n",
      "Bryce Drew\n",
      "Pat Garrity\n",
      "Roshown McLeod\n",
      "Ricky Davis\n",
      "Brian Skinner\n",
      "Tyronn Lue\n",
      "Felipe Lopez\n",
      "Sam Jacobson\n",
      "Corey Benjamin\n",
      "Nazr Mohammed\n",
      "END OF YEAR: 1998\n",
      "\n",
      "Elton Brand\n",
      "Steve Francis\n",
      "Baron Davis\n",
      "Lamar Odom\n",
      "Wally Szczerbiak\n",
      "Richard Hamilton\n",
      "Andre Miller\n",
      "Shawn Marion\n",
      "Jason Terry\n",
      "Trajan Langdon
